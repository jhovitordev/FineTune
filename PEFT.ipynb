{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cd1c5ff-50ec-4fe0-8156-e21c619f8ecc",
   "metadata": {},
   "source": [
    "## Ajuste fino eficiente de parâmetros (PEFT) com LoRA\n",
    "\n",
    " Realizar o treinamento de LLMs demanda um custo computacional significativo, pois é importante considerar que o ajuste fino completo requer memória muitas vezes maior do que o próprio modelo, devido à necessidade de armazenamento de diversos outros parâmetros durante o processo de ajuste. Além disso, é essencial alocar memória para estados do otimizador, gradientes, ativações futuras e memória temporária ao longo de todo o treinamento. Esses componentes adicionais podem exceder rapidamente a capacidade do hardware de consumo. Neste contexto, os Large Language Models (LLMs) como GPT-4 ou LLaMA, onde o pré-treinamento envolve conjuntos de dados massivos, o ponto de partida para o ajuste fino é uma rede neural com bilhões de pesos. O ajuste fino de tal modelo é quase impossível sem grandes quantidades de computação, e é aqui que entram LoRA e QLoRA! Essas técnicas democratizam o acesso à IA generativa e são essenciais para quem deseja personalizar um LLM pré-treinado de maneira econômica.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc591b-9c2f-4d47-b6c0-d6a27ccfe68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers[torch]\n",
    "!pip install pandas peft datasets\n",
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "281c15ac-7f35-4433-93f5-8b4b3716cb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForPreTraining, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset, Dataset\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "206eb413-8d02-4ffe-95cf-f48f214e08f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurando Lora logo:\n",
    "peft_config = LoraConfig(\n",
    "    task_type = TaskType.CAUSAL_LM,\n",
    "    inference_mode = False,\n",
    "    r = 8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdefe423-085b-47d4-aca2-ea54255e7c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chamando o modelo\n",
    "model_name = 'bigscience/bloom-560m'\n",
    "model = AutoModelForPreTraining.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "lora_model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1149fd2f-e225-4f46-b919-b92e542fd7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = {\"train\": \"./Dados/treino.csv\", \"test\":'./Dados/teste.csv'}\n",
    "dataSetCompleto = load_dataset(\"csv\", data_files=data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5355c7db-0578-435e-b611-cb2714f4c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os dados de treino e teste\n",
    "dataset_treino = dataSetCompleto['train']\n",
    "dataset_teste = dataSetCompleto['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a9785c-a673-4fde-b713-2d925006e8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realziando a Toikenização dos dados para passar para o trinamento\n",
    "def tokenizar(dados):\n",
    "    return tokenizer(dados[\"pergunta\"], dados[\"resposta\"], truncation=True, padding=\"longest\")\n",
    "\n",
    "train_dataset = dataset_treino.map(tokenizar, batched=True)\n",
    "test_dataset = dataset_teste.map(tokenizar, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "554181af-bd3d-497b-98b2-4835fd06b8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A função DataCollatorForLanguageModeling() \n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1795eeff-4623-4c46-9e3f-ab9f3a811de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_prediction):\n",
    "  loss = eval_prediction.loss\n",
    "  perplexity = torch.exp(torch.tensor(loss)).item()\n",
    "  return {\"perplexity\": perplexity, \"eval_loss\": loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a85ab24-4ef1-4157-ba1a-265296c84422",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./novaPasta\", \n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    eval_strategy='epoch',\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d1b0f47-12ab-45ef-9591-c2a8c4e33f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dataset_teste,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ad1695-5f96-4f5a-a0c4-93cb74fa9d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d58a8e-016e-4d95-8e22-b4b99fce1909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvando o modelo ajustado em uma pasta\n",
    "output_model_dir = \"./novaPasta\"\n",
    "model.save_pretrained(output_model_dir)\n",
    "tokenizer.save_pretrained(output_model_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
